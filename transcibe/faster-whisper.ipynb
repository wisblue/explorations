{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using insanely-fast-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/Vaibhavs10/insanely-fast-whisper/blob/main/notebooks/infer_transformers_whisper_large_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"automatic-speech-recognition\",\n",
    "                \"openai/whisper-large-v2\",\n",
    "                torch_dtype=torch.float16,\n",
    "                device=\"cuda:0\")\n",
    "pipe.model = pipe.model.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_url = 'I-have-a-dream.wav'\n",
    "speech, sr = librosa.load(audio_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have a dream that my four little children will one day be in a nation where they will not be judged by the color of their skin, but by the content of their character.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = pipe(speech,\n",
    "               chunk_length_s=30,\n",
    "               batch_size=16,\n",
    "               return_timestamps=False)\n",
    "\n",
    "print(outputs[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using faster_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"large-v3\"\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, \n",
    "                     # device=\"cuda\", \n",
    "                     compute_type=\"float16\")\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 0.893066\n",
      "[0.00s -> 20.41s]  I have a dream that my four little children will one day be with a nation where they will not judged by the color of their skin, but by the content of their character.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import librosa\n",
    "\n",
    "audio_url = 'I-have-a-dream.wav'\n",
    "speech, sr = librosa.load(audio_url)\n",
    "segments, info = model.transcribe(speech, \n",
    "                                  beam_size=5,\n",
    "                                  without_timestamps=True,\n",
    "                                  word_timestamps=False\n",
    "                                  )\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
